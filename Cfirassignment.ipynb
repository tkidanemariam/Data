{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model CIFAR 10 Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we'll model the CIFAR 10 image recognition dataset in python. The input is all set up for you, but its up to you to build the network. \n",
    "\n",
    "First we'll import all the libraries we'll need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT IMPORTANT IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the line below to point to the cifar-10-python.tar datafile that you downloaded in the zip with this example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir: 'Users/tsehay/Desktop/SVHM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT IMPORTANT IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all boilerplate that imports all the data. It should tun all in one go AS LONG AS you've set the directory above correctly, and included the double slashes (\"\\\\\\\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "tarFile = tarfile.open('cifar-10-python.tar')\n",
    "\n",
    "tarFile.getnames()\n",
    "\n",
    "tarFile.extractall()\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for name in tarFile.getnames():\n",
    "    if name == 'cifar-10-batches-py/readme.html':\n",
    "        continue\n",
    "    elif name == 'cifar-10-batches-py/batches.meta':\n",
    "        continue\n",
    "    elif name == 'cifar-10-batches-py':\n",
    "        continue\n",
    "    elif name == 'cifar-10-batches-py/test_batch':\n",
    "        testData = unpickle(name)\n",
    "        test_x = testData[b'data']\n",
    "        test_y = testData[b'labels']\n",
    "    else:\n",
    "        tempDict = unpickle(name)\n",
    "        train_x.extend(tempDict[b'data'])\n",
    "        train_y.extend(tempDict[b'labels'])\n",
    "\n",
    "# Matrix shape is 3072, which is three matrixes of 32*32 (1024 units), one for each color\n",
    "\n",
    "# The training sets are train_x (data) and train_y (labels)\n",
    "# The test sets are test_x (data) and test_y (labels)\n",
    "\n",
    "# last thing is to convert this into an array, so we can use it to train our model. \n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "train_y = keras.utils.to_categorical(train_y, 10)\n",
    "\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n",
    "test_y = keras.utils.to_categorical(test_y, 10)\n",
    "\n",
    "\n",
    "# Rearrange the flat items into a matrix so we can use a CNN to predict the values. \n",
    "\n",
    "train_x_v2 = [np.concatenate((x[:1024].reshape(1, -1, 32), x[1024:2048].reshape(1, -1, 32), x[2048:].reshape(1, -1, 32)), axis = 0) for x in train_x]\n",
    "train_x_v2 = np.array(train_x_v2)\n",
    "\n",
    "test_x_v2 = [np.concatenate((x[:1024].reshape(1, -1, 32), x[1024:2048].reshape(1, -1, 32), x[2048:].reshape(1, -1, 32)), axis = 0) for x in test_x]\n",
    "test_x_v2 = np.array(test_x_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import all the Keras parts you need, and start building your network. We've included some for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, Dropout  \n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build your network! Here are some tips: \n",
    "- The input shape is (3, 32, 32)\n",
    "- You'll want to use 2D layers (Conv2D, MaxPooling2D, etc.)\n",
    "- The kernel_size argument for 2D layers is a tuple like this (5, 5)\n",
    "\n",
    "So insead of kernel_size = 5 (in the example), you'll say kernel_size = (5, 5). This imput is still tunable. \n",
    "\n",
    "And finally - here is your canvas! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To start you off: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here is a simple network with a single set of hidden layers and all the basics you need to get started. You can experiment by extending this network, changing the value of the parameters, adding (or removing) layers, etc. For a good grade, you WILL need to get creative, and record the imapct the changes have on accuracy, on training time, etc.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64, kernel_size = (2, 2),  input_shape = (3, 32, 32), data_format = 'channels_first'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = keras.optimizers.Adadelta(), \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16768/50000 [=========>....................] - ETA: 3:22 - loss: 5.1985 - acc: 0.2198"
     ]
    }
   ],
   "source": [
    "model.fit(train_x_v2, train_y, epochs = 10, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x_v2, test_y)\n",
    "print('\\nloss is: ' + str(score[0].round(4)))\n",
    "print('accuracy is: ' + str(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
